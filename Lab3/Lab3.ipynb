{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "\n",
    "## Setup for this lab\n",
    "\n",
    "1. Download the data from the following link: https://smu.box.com/s/smqmwlef0yehpieicwxqdr99k7f9ru04\n",
    "2. Extract the downloaded data into Lab3/data\n",
    "3. Run the `query.py` script in the data folder\n",
    "4. Install RDKit for Python: https://www.rdkit.org/docs/Install.html\n",
    "\n",
    "NOTE: I found it significantly easier to download RDKit using the apt package for Ubuntu. However, this installed the Python2 version of RDKit instead of the Python3 version. If you are using Python3, the only difference is reading in the data using pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import MACCSkeys, AllChem\n",
    "from rdkit.Chem import ChemicalFeatures\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit import RDConfig\n",
    "import os\n",
    "import pickle\n",
    "from random import shuffle\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load(open('data/data.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(X).head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove values in the middle\n",
    "df = df[(df.ic50.astype(float) > 10000) | (df.ic50.astype(float) < 300)]\n",
    "\n",
    "# binarize ic50\n",
    "df.ic50 = df.ic50.astype(float) < 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_morgan_fingerprints(smiles):\n",
    "    fdefName = os.path.join(RDConfig.RDDataDir,'BaseFeatures.fdef')\n",
    "    factory = ChemicalFeatures.BuildFeatureFactory(fdefName)\n",
    "    fps = []\n",
    "    for smile in smiles:\n",
    "        m = Chem.MolFromSmiles(smile)\n",
    "        if m is not None:\n",
    "            fps.append(AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=512))\n",
    "        else:\n",
    "            fps.append(None)\n",
    "    return fps\n",
    "\n",
    "def get_topological_fingerprints(smiles):\n",
    "    fdefName = os.path.join(RDConfig.RDDataDir,'BaseFeatures.fdef')\n",
    "    factory = ChemicalFeatures.BuildFeatureFactory(fdefName)\n",
    "    fps = []\n",
    "    for smile in smiles:\n",
    "        m = Chem.MolFromSmiles(smile)\n",
    "        if m is not None:\n",
    "            fps.append(FingerprintMols.FingerprintMol(m))\n",
    "        else:\n",
    "            fps.append(None)\n",
    "    return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build feature factory\n",
    "fdefName = os.path.join(RDConfig.RDDataDir,'BaseFeatures.fdef')\n",
    "factory = ChemicalFeatures.BuildFeatureFactory(fdefName)\n",
    "\n",
    "#fps = []\n",
    "#all_smiles = df.smiles\n",
    "df['morgan_fps'] = get_morgan_fingerprints(df.smiles)\n",
    "df['topological_fps'] = get_topological_fingerprints(df.smiles)\n",
    "df = df[df.morgan_fps != None]\n",
    "df = df.drop(columns=['smiles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uq_targets = set(df.target)\n",
    "target_data = {}\n",
    "for target in uq_targets:\n",
    "    target_data[target] = [[],[],[]]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    morgan = np.zeros((1,))\n",
    "    topo = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(row.morgan_fps, morgan)\n",
    "    DataStructs.ConvertToNumpyArray(row.topological_fps, topo)\n",
    "    target_data[row.target][0].append(morgan)\n",
    "    target_data[row.target][1].append(topo)\n",
    "    target_data[row.target][2].append(row.ic50)\n",
    "\n",
    "for target in target_data.keys():\n",
    "    target_data[target][0] = np.array(target_data[target][0])\n",
    "    target_data[target][1] = np.array(target_data[target][1])\n",
    "    target_data[target][2] = np.array(target_data[target][2])*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now saved in a dictionary called `target_data`. This dictionary contains one entry per target. For each target, there is a list that contains three values: a numpy array with the morgan fingerprints, a numpy array with the topological fingerprints, and a numpy array with the binary binding affinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models(input_shape, target_names):\n",
    "    model_input = Input(input_shape)\n",
    "    shared_layers = Dense(512, activation='relu')(model_input)\n",
    "    shared_layers = Dense(1024, activation='relu')(shared_layers)\n",
    "    shared_layers = Dense(1024, activation='relu')(shared_layers)\n",
    "    models = {}\n",
    "    for target_name in target_names:\n",
    "        specialized_layers = Dense(2048, activation='relu')(shared_layers)\n",
    "        output = Dense(1, activation='sigmoid')(specialized_layers)\n",
    "        models[target_name] = Model(model_input,output)\n",
    "        models[target_name].compile(loss='binary_crossentropy',optimizer='adam')\n",
    "    return models\n",
    "\n",
    "def train_models(target_data, models, epochs, batch_size, data_type='morgan'):\n",
    "    if data_type=='morgan':\n",
    "        data_index = 0\n",
    "    else:\n",
    "        data_index = 1\n",
    "    for epoch in range(epochs):\n",
    "        target_order = models.keys()\n",
    "        shuffle(target_order)\n",
    "        for target in target_order:\n",
    "            model = models[target]\n",
    "            x_data = target_data[target][data_index]\n",
    "            y_data = target_data[target][2]\n",
    "            model.fit(x_data, y_data, batch_size=batch_size, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_data[target_data.keys()[0]][0].shape\n",
    "\n",
    "models = build_models((512,), target_data.keys())\n",
    "\n",
    "train_models(target_data, models, 1, 2, 'morgan')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
